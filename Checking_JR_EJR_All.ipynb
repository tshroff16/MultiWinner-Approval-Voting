{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a11667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File_path:  pablulib2\\artificial_mechanical-turk_k-approval-3_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_k-approval-6_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_k-approval-7_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_k-approval-8_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_knapsack-3_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_knapsack-6_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_knapsack-7_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_knapsack-8_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_threshold-3_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_threshold-6_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_threshold-7_.pb\n",
      "File_path:  pablulib2\\artificial_mechanical-turk_threshold-8_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_166_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_179_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_212_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_252_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_267_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_285_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_287_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_288_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_289_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_304_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_309_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_324_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_332_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_335_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_358_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_417_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_489_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_490_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_491_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_492_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_509_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_515_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_522_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_523_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_524_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_525_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_588_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_604_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_605_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_613_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_619_.pb\n",
      "File_path:  pablulib2\\netherlands_amsterdam_621_.pb\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 155\u001b[0m\n\u001b[0;32m    152\u001b[0m         result1, duration1 \u001b[38;5;241m=\u001b[39m JR(non_winners, approval_dict, W_set, k, n)\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;66;03m# Check for EJR\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m         result2, duration2 \u001b[38;5;241m=\u001b[39m \u001b[43mEJR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapproval_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         results_single_file\u001b[38;5;241m.\u001b[39mappend((l, W_value, result1, duration1, result2, duration2))\n\u001b[0;32m    159\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results_single_file, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJR Duration\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEJR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEJR Duration\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m, in \u001b[0;36mEJR\u001b[1;34m(approval_lists, winners, k, n, C, l)\u001b[0m\n\u001b[0;32m     51\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m approval_list \u001b[38;5;129;01min\u001b[39;00m approval_lists\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39missubset(approval_list):\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(approval_list) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(winners))) \u001b[38;5;241m<\u001b[39m l:\n\u001b[0;32m     55\u001b[0m             count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from itertools import chain, combinations\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Define functions for JR, EJR, and other operations\n",
    "\n",
    "def powerset(iterable, max_size):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, min(len(s)+1, max_size+1)))\n",
    "\n",
    "def subset_of_len_l(C_modified, l):\n",
    "    return set(combinations(C_modified, l))\n",
    "\n",
    "def create_set_W(df, W):\n",
    "    return set(df.head(W)['Value'])\n",
    "\n",
    "def JR(non_winners, approval_dict, W_set, k, n):\n",
    "    start_time = time.time()  # Record start time\n",
    "    duration = 0  # Initialize duration\n",
    "\n",
    "    counts = {}\n",
    "    breaks_jr = False\n",
    "\n",
    "    for non_winner in non_winners:\n",
    "        counts[non_winner] = 0\n",
    "        for key, value in approval_dict.items():\n",
    "            if non_winner in value and not set(W_set).intersection(value):\n",
    "                counts[non_winner] += 1\n",
    "                if counts[non_winner] >= n / k:\n",
    "                    breaks_jr = True\n",
    "                    break\n",
    "        if breaks_jr:\n",
    "            duration = time.time() - start_time\n",
    "            return 0, duration  # Return a tuple\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    return 1, duration  # Return a tuple\n",
    "\n",
    "\n",
    "def EJR(approval_lists, winners, k, n, C,l):\n",
    "    start_time = time.time()  # Record start time\n",
    "    \n",
    "    C_modified = [candidate for candidate in C if greedy_list.loc[greedy_list['Value'] == candidate, 'Count'].iloc[0] >= l * n / k]\n",
    "    S = subset_of_len_l(C_modified, l)\n",
    "\n",
    "    for s in S:\n",
    "        count = 0\n",
    "        for approval_list in approval_lists.values():\n",
    "            if set(s).issubset(approval_list):\n",
    "                if abs(len(set(approval_list) & set(winners))) < l:\n",
    "                    count += 1\n",
    "        if count >= l * n / k:\n",
    "            end_time = time.time()  # Record end time\n",
    "            duration = end_time - start_time  # Calculate duration\n",
    "            return 0, duration\n",
    "                \n",
    "    end_time = time.time()  # Record end time\n",
    "    duration = end_time - start_time  # Calculate duration\n",
    "    return 1, duration\n",
    "\n",
    "# Directory where input files are stored\n",
    "input_directory = 'pablulib2'\n",
    "\n",
    "# List of file paths\n",
    "file_paths = []\n",
    "\n",
    "# Read all file paths from the directory\n",
    "for root, dirs, files in os.walk(input_directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pb\"):\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "\n",
    "# Directory where result files will be saved\n",
    "results_directory = 'results_pabulib'\n",
    "os.makedirs(results_directory, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "summary_results = []\n",
    "\n",
    "# Iterate over each file path\n",
    "for file_path in file_paths:\n",
    "    print(\"File_path: \", file_path)\n",
    "    with open(file_path, 'r', newline='', encoding=\"utf-8\") as csvfile:\n",
    "        meta = {}\n",
    "        projects = {}\n",
    "        votes = {}\n",
    "        section = \"\"\n",
    "        header = []\n",
    "        reader = csv.reader(csvfile, delimiter=';')\n",
    "        for row in reader:\n",
    "            if str(row[0]).strip().lower() in [\"meta\", \"projects\", \"votes\"]:\n",
    "                section = str(row[0]).strip().lower()\n",
    "                header = next(reader)\n",
    "            elif section == \"meta\":\n",
    "                meta[row[0]] = row[1].strip()\n",
    "            elif section == \"projects\":\n",
    "                projects[row[0]] = {}\n",
    "                for it, key in enumerate(header[1:]):\n",
    "                    projects[row[0]][key.strip()] = row[it+1].strip()\n",
    "            elif section == \"votes\":\n",
    "                votes[row[0]] = {}\n",
    "                for it, key in enumerate(header[1:]):\n",
    "                    votes[row[0]][key.strip()] = row[it+1].strip()\n",
    "\n",
    "    # Extract required data and perform operations as before...\n",
    "    \n",
    "    C = set(projects.keys())\n",
    "    V = set(votes.keys())\n",
    "    n = len(V)\n",
    "    approval_dict = {key: set(value['vote'].split(',')) for key, value in votes.items()}\n",
    "\n",
    "    lengths = [len(value) for value in approval_dict.values()]\n",
    "\n",
    "    # Calculate the average length\n",
    "    average_length = sum(lengths) / len(lengths)\n",
    "\n",
    "    #print(\"Average length of values:\", average_length)\n",
    "\n",
    "    max_length = min(len(value) for value in approval_dict.values())\n",
    "\n",
    "    # Creating a DataFrame with the projects and the number of votes they got\n",
    "    all_values = set()\n",
    "    for value_set in approval_dict.values():\n",
    "        all_values.update(value_set)\n",
    "\n",
    "    # Count occurrences of each value in the entire dictionary\n",
    "    count_dict = Counter()\n",
    "    for value_set in approval_dict.values():\n",
    "        count_dict.update(value_set)\n",
    "\n",
    "    # Create a list with unique values and their counts\n",
    "    result_list = [[value, count_dict[value]] for value in all_values]\n",
    "\n",
    "    greedy_list = pd.DataFrame(result_list, columns=['Value', 'Count'])\n",
    "    greedy_list = greedy_list.sort_values(by='Count', ascending=False)\n",
    "\n",
    "    W_range = range(1, 11)\n",
    "    results_single_file = []\n",
    "\n",
    "    # Iterate over different values of W\n",
    "    for l in W_range:\n",
    "        for W_value in W_range:\n",
    "            W_set = create_set_W(greedy_list, W_value)\n",
    "            k = len(W_set)\n",
    "            non_winners = C - W_set\n",
    "\n",
    "            # Check for JR\n",
    "            result1, duration1 = JR(non_winners, approval_dict, W_set, k, n)\n",
    "\n",
    "            # Check for EJR\n",
    "            result2, duration2 = EJR(approval_dict, W_set, k, n, C, l)\n",
    "\n",
    "            results_single_file.append((l, W_value, result1, duration1, result2, duration2))\n",
    "\n",
    "    results_df = pd.DataFrame(results_single_file, columns=['l', 'k', 'JR', 'JR Duration', 'EJR', 'EJR Duration'])\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    file_name = os.path.splitext(os.path.basename(file_path))[0] + '_results.csv'\n",
    "    results_path = os.path.join(results_directory, file_name)\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # Append results for each file path to the results list\n",
    "    results.append(results_df)\n",
    "\n",
    "# Concatenate results from all files into one dataframe\n",
    "all_results_df = pd.concat(results)\n",
    "\n",
    "# Calculate percentage of distinct values of column 'k' where 'jr' column is 1\n",
    "jr_column_1_count = all_results_df[all_results_df['JR'] == 1].groupby('k').size().reset_index(name='jr_1_count')\n",
    "\n",
    "# Calculate percentage of distinct values of column 'k' where 'ejr' column is 1\n",
    "ejr_column_1_count = all_results_df[all_results_df['EJR'] == 1].groupby('k').size().reset_index(name='ejr_1_count')\n",
    "\n",
    "# Merge the counts for 'jr' and 'ejr' by 'k'\n",
    "merged_counts = pd.merge(jr_column_1_count, ejr_column_1_count, on='k', how='outer').fillna(0)\n",
    "\n",
    "# Calculate the total distinct values of 'k' across all files\n",
    "# total_distinct_k_values = len(set(merged_counts['k']))\n",
    "total_distinct_k_values = len(set(merged_counts['k']))\n",
    "# Calculate percentage of 'jr' and 'ejr' being 1 for each 'k'\n",
    "merged_counts['jr_percentage'] = (merged_counts['jr_1_count'] / total_distinct_k_values) * 100\n",
    "merged_counts['ejr_percentage'] = (merged_counts['ejr_1_count'] / total_distinct_k_values) * 100\n",
    "\n",
    "# Display the summary\n",
    "print(\"Summary for all files:\")\n",
    "print(merged_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5910d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l</th>\n",
       "      <th>k</th>\n",
       "      <th>JR</th>\n",
       "      <th>JR Duration</th>\n",
       "      <th>EJR</th>\n",
       "      <th>EJR Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   l  k  JR  JR Duration  EJR  EJR Duration\n",
       "0  1  1   0     0.000998    1      0.004781\n",
       "1  1  2   0     0.002992    1      0.003989\n",
       "2  1  3   0     0.001996    1      0.006980\n",
       "3  1  4   0     0.000998    1      0.007978\n",
       "4  1  5   0     0.001995    1      0.008076"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c79580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58d1fe63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1760"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_distinct_k_values = len(file_paths) * 10\n",
    "total_distinct_k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f62fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pabulib_files_2\\artificial_mechanical-turk_k-approval-3_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_k-approval-6_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_k-approval-7_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_k-approval-8_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_knapsack-3_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_knapsack-6_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_knapsack-7_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_knapsack-8_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_threshold-3_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_threshold-6_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_threshold-7_.pb\n",
      "pabulib_files_2\\artificial_mechanical-turk_threshold-8_.pb\n",
      "pabulib_files_2\\netherlands_amsterdam_166_.pb\n",
      "pabulib_files_2\\netherlands_amsterdam_179_.pb\n",
      "pabulib_files_2\\netherlands_amsterdam_212_.pb\n",
      "pabulib_files_2\\netherlands_amsterdam_252_.pb\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from itertools import chain, combinations\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Define functions for JR, EJR, and other operations\n",
    "\n",
    "def powerset(iterable, max_size):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, min(len(s)+1, max_size+1)))\n",
    "\n",
    "def subset_of_len_l(C_modified, l):\n",
    "    return set(combinations(C_modified, l))\n",
    "\n",
    "def create_set_W(df, W):\n",
    "    return set(df.head(W)['Value'])\n",
    "\n",
    "def JR(non_winners, approval_dict, W_set, k, n):\n",
    "    start_time = time.time()  # Record start time\n",
    "    duration = 0  # Initialize duration\n",
    "\n",
    "    counts = {}\n",
    "    breaks_jr = False\n",
    "\n",
    "    for non_winner in non_winners:\n",
    "        counts[non_winner] = 0\n",
    "        for key, value in approval_dict.items():\n",
    "            if non_winner in value and not set(W_set).intersection(value):\n",
    "                counts[non_winner] += 1\n",
    "                if counts[non_winner] >= n / k:\n",
    "                    breaks_jr = True\n",
    "                    break\n",
    "    if breaks_jr:\n",
    "        duration = time.time() - start_time\n",
    "        return 0, duration  # Return a tuple\n",
    "    else:\n",
    "        duration = time.time() - start_time\n",
    "        return 1, duration  # Return a tuple\n",
    "\n",
    "\n",
    "def EJR(approval_lists, winners, k, n, C,l):\n",
    "    start_time = time.time()  # Record start time\n",
    "    \n",
    "    C_modified = [candidate for candidate in C if greedy_list.loc[greedy_list['Value'] == candidate, 'Count'].iloc[0] >= l * n / k]\n",
    "    S = subset_of_len_l(C_modified, l)\n",
    "\n",
    "    for s in S:\n",
    "        count = 0\n",
    "        for approval_list in approval_lists.values():\n",
    "            if set(s).issubset(approval_list):\n",
    "                if abs(len(set(approval_list) & set(winners))) < l:\n",
    "                    count += 1\n",
    "        if count >= l * n / k:\n",
    "            end_time = time.time()  # Record end time\n",
    "            duration = end_time - start_time  # Calculate duration\n",
    "            return 0, duration\n",
    "                \n",
    "    end_time = time.time()  # Record end time\n",
    "    duration = end_time - start_time  # Calculate duration\n",
    "    return 1, duration\n",
    "\n",
    "# Directory where input files are stored\n",
    "input_directory = 'pabulib_files_2'\n",
    "\n",
    "# List of file paths\n",
    "file_paths = []\n",
    "\n",
    "# Read all file paths from the directory\n",
    "for root, dirs, files in os.walk(input_directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pb\"):\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "\n",
    "# Directory where result files will be saved\n",
    "results_directory = 'results_pabulib'\n",
    "os.makedirs(results_directory, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "summary_results = []\n",
    "\n",
    "# Iterate over each file path\n",
    "for file_path in file_paths:\n",
    "    print(file_path)\n",
    "    with open(file_path, 'r', newline='', encoding=\"utf-8\") as csvfile:\n",
    "        meta = {}\n",
    "        projects = {}\n",
    "        votes = {}\n",
    "        section = \"\"\n",
    "        header = []\n",
    "        reader = csv.reader(csvfile, delimiter=';')\n",
    "        for row in reader:\n",
    "            if str(row[0]).strip().lower() in [\"meta\", \"projects\", \"votes\"]:\n",
    "                section = str(row[0]).strip().lower()\n",
    "                header = next(reader)\n",
    "            elif section == \"meta\":\n",
    "                meta[row[0]] = row[1].strip()\n",
    "            elif section == \"projects\":\n",
    "                projects[row[0]] = {}\n",
    "                for it, key in enumerate(header[1:]):\n",
    "                    projects[row[0]][key.strip()] = row[it+1].strip()\n",
    "            elif section == \"votes\":\n",
    "                votes[row[0]] = {}\n",
    "                for it, key in enumerate(header[1:]):\n",
    "                    votes[row[0]][key.strip()] = row[it+1].strip()\n",
    "\n",
    "    # Extract required data and perform operations as before...\n",
    "    \n",
    "    C = set(projects.keys())\n",
    "    V = set(votes.keys())\n",
    "    n = len(V)\n",
    "    approval_dict = {key: set(value['vote'].split(',')) for key, value in votes.items()}\n",
    "\n",
    "    lengths = [len(value) for value in approval_dict.values()]\n",
    "\n",
    "    # Calculate the average length\n",
    "    average_length = sum(lengths) / len(lengths)\n",
    "\n",
    "    #print(\"Average length of values:\", average_length)\n",
    "\n",
    "    max_length = min(len(value) for value in approval_dict.values())\n",
    "\n",
    "    # Creating a DataFrame with the projects and the number of votes they got\n",
    "    all_values = set()\n",
    "    for value_set in approval_dict.values():\n",
    "        all_values.update(value_set)\n",
    "\n",
    "    # Count occurrences of each value in the entire dictionary\n",
    "    count_dict = Counter()\n",
    "    for value_set in approval_dict.values():\n",
    "        count_dict.update(value_set)\n",
    "\n",
    "    # Create a list with unique values and their counts\n",
    "    result_list = [[value, count_dict[value]] for value in all_values]\n",
    "\n",
    "    greedy_list = pd.DataFrame(result_list, columns=['Value', 'Count'])\n",
    "    greedy_list = greedy_list.sort_values(by='Count', ascending=False)\n",
    "\n",
    "    W_range = range(1, 11)\n",
    "    results_single_file = []\n",
    "\n",
    "    # Iterate over different values of W\n",
    "    for l in W_range:\n",
    "        for W_value in W_range:\n",
    "            W_set = create_set_W(greedy_list, W_value)\n",
    "            k = len(W_set)\n",
    "            non_winners = C - W_set\n",
    "\n",
    "            # Check for JR\n",
    "            result1, duration1 = JR(non_winners, approval_dict, W_set, k, n)\n",
    "\n",
    "            # Check for EJR\n",
    "            result2, duration2 = EJR(approval_dict, W_set, k, n, C, l)\n",
    "\n",
    "            results_single_file.append((l, W_value, result1, duration1, result2, duration2))\n",
    "\n",
    "    results_df = pd.DataFrame(results_single_file, columns=['l', 'k', 'JR', 'JR Duration', 'EJR', 'EJR Duration'])\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    file_name = os.path.splitext(os.path.basename(file_path))[0] + '_results.csv'\n",
    "    results_path = os.path.join(results_directory, file_name)\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # Append results for each file path to the results list\n",
    "    results.append(results_df)\n",
    "\n",
    "# Concatenate results from all files into one dataframe\n",
    "all_results_df = pd.concat(results)\n",
    "\n",
    "# Calculate percentage of distinct values of column 'k' where 'jr' column is 1\n",
    "jr_column_1_count = all_results_df[all_results_df['JR'] == 1].groupby('k').size().reset_index(name='jr_1_count')\n",
    "\n",
    "# Calculate percentage of distinct values of column 'k' where 'ejr' column is 1\n",
    "ejr_column_1_count = all_results_df[all_results_df['EJR'] == 1].groupby('k').size().reset_index(name='ejr_1_count')\n",
    "\n",
    "# Merge the counts for 'jr' and 'ejr' by 'k'\n",
    "merged_counts = pd.merge(jr_column_1_count, ejr_column_1_count, on='k', how='outer').fillna(0)\n",
    "\n",
    "# Calculate the total distinct values of 'k' across all files\n",
    "# total_distinct_k_values = len(set(merged_counts['k']))\n",
    "total_distinct_k_values = len(file_paths) * 10\n",
    "# Calculate percentage of 'jr' and 'ejr' being 1 for each 'k'\n",
    "merged_counts['jr_percentage'] = (merged_counts['jr_1_count'] / total_distinct_k_values) * 100\n",
    "merged_counts['ejr_percentage'] = (merged_counts['ejr_1_count'] / total_distinct_k_values) * 100\n",
    "\n",
    "# Display the summary\n",
    "print(\"Summary for all files:\")\n",
    "print(merged_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0880aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l</th>\n",
       "      <th>k</th>\n",
       "      <th>JR</th>\n",
       "      <th>JR Duration</th>\n",
       "      <th>EJR</th>\n",
       "      <th>EJR Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105674</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.151017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089854</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606285</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590395</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687107</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.587982</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13700 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     l   k  JR  JR Duration  EJR  EJR Duration\n",
       "0    1   1   1     0.047889    1      0.016202\n",
       "1    1   2   1     0.105674    1      0.024516\n",
       "2    1   3   1     0.151017    1      0.027596\n",
       "3    1   4   1     0.131291    1      0.106275\n",
       "4    1   5   1     0.089854    1      0.090339\n",
       "..  ..  ..  ..          ...  ...           ...\n",
       "95  10   6   1     0.475794    1      0.070637\n",
       "96  10   7   1     0.606285    1      0.100729\n",
       "97  10   8   1     0.590395    1      0.106048\n",
       "98  10   9   1     0.687107    1      0.100430\n",
       "99  10  10   1     0.587982    1      0.093890\n",
       "\n",
       "[13700 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5ec5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
